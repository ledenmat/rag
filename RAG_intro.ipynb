{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Retrieval-Augmented Generation (RAG) Workflows\n",
    "\n",
    "In this notebook, we will explore common workflows for Retrieval-Augmented Generation (RAG). RAG is a powerful technique that combines the strengths of information retrieval and natural language generation to produce more accurate and contextually relevant responses when compared to classic LLM generation. This approach is particularly useful in scenarios where the model needs to generate responses based on a large corpus of documents or knowledge base.\n",
    "\n",
    "## Objectives\n",
    "- Understand the basic concepts of Retrieval-Augmented Generation.\n",
    "- Learn how to set up a retrieval system to fetch relevant documents.\n",
    "- Integrate the retrieval system with a generation model to produce augmented responses.\n",
    "- Explore different use cases and applications of RAG.\n",
    "\n",
    "## Prerequisites\n",
    "- Very basic understanding of natural language processing (NLP) and machine learning.\n",
    "- Familiarity with Python programming.\n",
    "\n",
    "## Notebook Overview\n",
    "1. **Data Preparation**: Load and preprocess the corpus of documents.\n",
    "2. **Data Transformation**: Explore tokenization and vector embeddings.\n",
    "3. **Simple Retrieval System Setup**: Implement a simple vector-based retrieval system to fetch relevant documents based on a query.\n",
    "4. **Generative Model Integration**: Combine the simple retrieval system with a generation model to produce responses.\n",
    "5. **Advanced Retrieval System Setup**: Implement a more advanced retrieval system, using HNSW and BM25.\n",
    "6. **Try Prompt Tuning**: Experiment with different prompts and RAG variations.\n",
    "7. **Evaluation**: Assess the performance of the RAG system using appropriate metrics.\n",
    "\n",
    "Let's get started by setting up our environment and loading the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gensim in ./.venv/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in ./.venv/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./.venv/lib/python3.12/site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in ./.venv/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.12/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.12/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.12/site-packages (from datasets) (4.67.0)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./.venv/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.12/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./.venv/lib/python3.12/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./.venv/lib/python3.12/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu125/\n",
      "Collecting llama-cpp-python\n",
      "  Using cached llama_cpp_python-0.3.1.tar.gz (63.9 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.12/site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in ./.venv/lib/python3.12/site-packages (from llama-cpp-python) (1.26.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.1-cp312-cp312-linux_x86_64.whl size=3528036 sha256=fad89b9226d0903ad15aa579c1545bfb1d107cc6f56f5618e9ab1f2d04abaf00\n",
      "  Stored in directory: /home/cledenmat/.cache/pip/wheels/58/d4/b6/f219a2c6af82353b2a21923250728c3d180c95a5ad9ec1c6c3\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
      "Successfully installed MarkupSafe-3.0.2 diskcache-5.6.3 jinja2-3.1.4 llama-cpp-python-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests\n",
    "%pip install gensim\n",
    "%pip install datasets\n",
    "%pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu125/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the Ollama API endpoint and your model\n",
    "MODEL_API_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"llama3.1:8b\"\n",
    "EMBEDDING_API_URL = \"http://localhost:11434/api/embeddings\"\n",
    "EMBEDDING_MODEL_NAME = \"nomic-embed-text\"\n",
    "\n",
    "\n",
    "def generate_text(prompt):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"max_completion_tokens\": 256,  # Adjust max tokens for desired length\n",
    "        \"temperature\": 0.7,  # Adjust temperature for randomness\n",
    "        \"stream\": False,\n",
    "    }\n",
    "\n",
    "    response = requests.post(MODEL_API_URL, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"message\").get(\"content\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_embedding(prompt):\n",
    "    payload = {\n",
    "        \"model\": EMBEDDING_MODEL_NAME,\n",
    "        \"prompt\": prompt,\n",
    "    }\n",
    "\n",
    "    response = requests.post(EMBEDDING_API_URL, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"embedding\", \"\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Embeddings != Vector DB Embeddings\n",
    "\n",
    "Explanation of GenSim:\n",
    "\n",
    "    Tokenization: The sentences are split into tokens (words) and converted to lowercase.\n",
    "    Word2Vec Model: The Word2Vec model is trained with specified parameters:\n",
    "        vector_size: Size of the embedding vectors.\n",
    "        window: Maximum distance between the current and predicted word within a sentence. Specifically, it determines how many words to the left and right of the target word are included in the training examples.\n",
    "        min_count: Ignores all words with a total frequency lower than this.\n",
    "        sg: Skip-gram model if set to 1; CBOW if set to 0.\n",
    "    Getting Embeddings: The get_embedding function retrieves the embedding for a given word, with error handling for words not found in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text corpus: list of sentences\n",
    "sentences = [\n",
    "    \"The cat sat on the mat, enjoying the warm sun.\",\n",
    "    \"The dog sat on the log, watching the world go by.\",\n",
    "    \"Cats and dogs are both popular pets, each with unique characteristics.\",\n",
    "    \"I love my pets because they provide companionship and joy.\",\n",
    "    \"Pets bring joy to our lives and teach us responsibility.\",\n",
    "    \"Training pets can be a rewarding experience for both the owner and the animal.\",\n",
    "    \"Cats are often independent, while dogs typically seek companionship.\",\n",
    "    \"Many families consider pets as part of their family unit.\",\n",
    "    \"Adopting a pet can change your life and bring immense happiness.\",\n",
    "    \"Understanding pet behavior is key to building a strong bond with them.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'cat': [-3.3003380e-04  3.4521687e-05 -5.8911741e-04 ...  6.8755902e-04\n",
      " -2.3352924e-05 -7.8444142e-04]\n",
      "Embedding for 'dog': [-0.00025762  0.00087888 -0.00071964 ...  0.00081767  0.00016185\n",
      "  0.0008499 ]\n",
      "Embedding for 'pets': [ 3.8436285e-04  4.9113255e-04  5.9397717e-04 ... -8.1487949e-04\n",
      " -1.5125802e-05 -2.5849711e-04]\n",
      "Embedding for 'love': [-0.00066168 -0.00095225 -0.00059386 ... -0.00075696 -0.00030017\n",
      "  0.00017272]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokenization\n",
    "tokenized_sentences = [sentence.lower().split() for sentence in sentences]\n",
    "\n",
    "# Training the Word2Vec model\n",
    "model = Word2Vec(\n",
    "    sentences=tokenized_sentences, vector_size=1024, window=5, min_count=1, sg=0\n",
    ")\n",
    "\n",
    "\n",
    "# Getting token embeddings\n",
    "def get_embedding(word):\n",
    "    try:\n",
    "        return model.wv[word]\n",
    "    except KeyError:\n",
    "        print(f\"{word} not in vocabulary\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example of retrieving embeddings for specific words\n",
    "words_to_embed = [\"cat\", \"dog\", \"pets\", \"love\"]\n",
    "\n",
    "for word in words_to_embed:\n",
    "    embedding = get_embedding(word)\n",
    "    if embedding is not None:\n",
    "        print(f\"Embedding for '{word}': {embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: The cat sat on the mat, enjoying the warm sun.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: The dog sat on the log, watching the world go by.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: Cats and dogs are both popular pets, each with unique characteristics.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: I love my pets because they provide companionship and joy.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: Pets bring joy to our lives and teach us responsibility.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: Training pets can be a rewarding experience for both the owner and the animal.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: Cats are often independent, while dogs typically seek companionship.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: Many families consider pets as part of their family unit.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: Adopting a pet can change your life and bring immense happiness.\n",
      "Its embedding vector dimension: 768\n",
      "Original Sentence: Understanding pet behavior is key to building a strong bond with them.\n",
      "Its embedding vector dimension: 768\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = []\n",
    "for sentence in sentences:\n",
    "    sentence_embedding = generate_embedding(sentence)\n",
    "    sentence_embeddings.append(sentence_embedding)\n",
    "    print(\n",
    "        f\"Original Sentence: {sentence}\\nIts embedding vector dimension: {len(sentence_embedding)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RAG process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(vec_a, vec_b):\n",
    "    # Compute the dot product\n",
    "    dot_product = np.dot(vec_a, vec_b)\n",
    "\n",
    "    # Compute the magnitudes (norms) of the vectors\n",
    "    norm_a = np.linalg.norm(vec_a)\n",
    "    norm_b = np.linalg.norm(vec_b)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0  # Handle division by zero if any vector is zero\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def vector_db_search(query_embedding):\n",
    "    # Initialize variables to track the most similar text and its score\n",
    "    most_similar_text = \"\"\n",
    "    most_similar_score = -1\n",
    "\n",
    "    # Loop through the list of sentence embeddings to find the most similar one\n",
    "    for index, sentence_embedding in enumerate(sentence_embeddings):\n",
    "        # Compute cosine similarity between the question embedding and the current sentence embedding\n",
    "        computed_cosine_similarity = cosine_similarity(\n",
    "            query_embedding, sentence_embedding\n",
    "        )\n",
    "\n",
    "        # Check if the computed similarity is higher than the previous best score\n",
    "        if computed_cosine_similarity > most_similar_score:\n",
    "            most_similar_score = computed_cosine_similarity\n",
    "            most_similar_text = sentences[index]  # Update the most similar text\n",
    "\n",
    "    return (most_similar_text, most_similar_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our current sentences: ['The cat sat on the mat, enjoying the warm sun.', 'The dog sat on the log, watching the world go by.', 'Cats and dogs are both popular pets, each with unique characteristics.', 'I love my pets because they provide companionship and joy.', 'Pets bring joy to our lives and teach us responsibility.', 'Training pets can be a rewarding experience for both the owner and the animal.', 'Cats are often independent, while dogs typically seek companionship.', 'Many families consider pets as part of their family unit.', 'Adopting a pet can change your life and bring immense happiness.', 'Understanding pet behavior is key to building a strong bond with them.']\n",
      "\n",
      "Our query: 'How do families see pets?'\n",
      "Most similar sentence in our vector DB: 'Many families consider pets as part of their family unit.'\n",
      "Cosine Similarity Score: 0.8076\n",
      "\n",
      "### RAG GENERATION ###\n",
      "Families typically view pets as beloved members of their family, often including them in daily activities and showing affection towards them similar to how they treat other human family members.\n",
      "\n",
      "### REGULAR GENERATION ###\n",
      "The way families see pets has evolved significantly over the years, and it's now more commonly viewed as a integral part of family life. Here are some insights:\n",
      "\n",
      "**Changing attitudes:**\n",
      "\n",
      "1. **Pets as members of the family**: Many families now consider their pets to be full-fledged members of the household, deserving love, care, and attention.\n",
      "2. **Shift from \"pet\" to \"family member\"**: The term \"pet\" has given way to more affectionate terms like \"brother,\" \"sister,\" or even \"child.\"\n",
      "3. **Increased emotional involvement**: Families are more emotionally invested in their pets' well-being, often treating them as a source of comfort, companionship, and joy.\n",
      "\n",
      "**The role of pets in family life:**\n",
      "\n",
      "1. **Companions for children**: Pets provide a sense of security and companionship for kids, helping to develop social skills, empathy, and responsibility.\n",
      "2. **Support system for adults**: For many families, pets offer emotional support, stress relief, and a sense of companionship for parents as well.\n",
      "3. **Teaching opportunities**: Caring for pets can teach children important life lessons about responsibility, compassion, and the importance of caring for another living being.\n",
      "\n",
      "**Modern family dynamics:**\n",
      "\n",
      "1. **Increased pet ownership**: With more people working from home or having flexible schedules, families are more likely to bring pets into their homes.\n",
      "2. **Multigenerational households**: As family structures evolve, older generations may also take on a greater role in caring for pets, further solidifying the bond between grandparents and grandkids.\n",
      "3. **Social media influence**: Social media platforms have amplified the visibility of pet owners' lives, showcasing the special bonds between humans and animals.\n",
      "\n",
      "**The benefits:**\n",
      "\n",
      "1. **Improved mental health**: Interacting with pets has been shown to reduce stress, anxiety, and depression in both children and adults.\n",
      "2. **Better social skills**: Caring for pets can help kids develop essential social skills, such as empathy, communication, and cooperation.\n",
      "3. **Emotional intelligence**: Recognizing and responding to a pet's emotions can teach valuable lessons about emotional awareness and understanding.\n",
      "\n",
      "Overall, the way families see pets has evolved to include them as integral members of their households, providing companionship, support, and teaching opportunities for all family members.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Our current sentences: {sentences}\\n\")\n",
    "\n",
    "# User's question\n",
    "our_question = \"How do families see pets?\"\n",
    "\n",
    "# Generate an embedding for the user's question\n",
    "the_embedding_of_our_question = generate_embedding(our_question)\n",
    "\n",
    "# Query the vector DB\n",
    "most_similar_text, score = vector_db_search(the_embedding_of_our_question)\n",
    "\n",
    "# Print the user's question and the most similar sentence in a formatted way\n",
    "print(\n",
    "    f\"Our query: '{our_question}'\\n\"\n",
    "    f\"Most similar sentence in our vector DB: '{most_similar_text}'\\n\"\n",
    "    f\"Cosine Similarity Score: {score:.4f}\\n\"\n",
    ")\n",
    "\n",
    "# Prepare the prompt for the RAG model using the most similar text\n",
    "rag_prompt_template = f\"\"\"\n",
    "You are an assistant for question answering tasks. Use the information between the <context> </context> blocks to help answer the question. If you don't know, say 'I dunno'.\n",
    "\n",
    "Here is the user's question: {our_question}\n",
    "\n",
    "<context> {most_similar_text} </context>\n",
    "\"\"\"\n",
    "\n",
    "# Print the prompt for RAG generation\n",
    "print(\"### RAG GENERATION ###\")\n",
    "print(generate_text(rag_prompt_template))\n",
    "\n",
    "# Print the result of regular text generation based on the original question\n",
    "print(\"\\n### REGULAR GENERATION ###\")\n",
    "print(generate_text(our_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewrite Retrieve Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the characteristics, habits, and living situations of typical household pets?\n"
     ]
    }
   ],
   "source": [
    "# Original query\n",
    "original_query = \"Tell me about pets.\"\n",
    "\n",
    "# Step 1: Rewrite the query\n",
    "refined_prompt = generate_text(\n",
    "    \"Rewrite the following query to make it more specific: \"\n",
    "    + original_query\n",
    "    + \"--- Only return the rewritten query\"\n",
    ")\n",
    "\n",
    "print(refined_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate-Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some facts about pets:\n",
      "\n",
      "**General Facts**\n",
      "\n",
      "1. Over 60% of households in the United States have a pet.\n",
      "2. The most common pets kept by Americans are dogs, cats, and fish.\n",
      "\n",
      "**Pet Care and Health**\n",
      "\n",
      "3. A typical cat spends around 16-18 hours per day sleeping.\n",
      "4. Dogs can hear sounds at frequencies as high as 45,000 Hz, while humans can only hear up to 20,000 Hz.\n",
      "5. The average lifespan of a domestic cat is 12-17 years.\n",
      "6. Some pets, such as birds and small mammals, are susceptible to stress-related behaviors if not properly socialized.\n",
      "\n",
      "**Pet Ownership Benefits**\n",
      "\n",
      "7. Studies have shown that owning a pet can lower blood pressure, cholesterol levels, and heart rate.\n",
      "8. Children who grow up in households with pets tend to develop a stronger immune system.\n",
      "9. Pet owners often experience reduced anxiety and depression symptoms compared to non-pet owners.\n",
      "\n",
      "**Interesting Pet Behaviors**\n",
      "\n",
      "10. Dogs have a unique nose print, just like human fingerprints.\n",
      "11. Cats can't taste sweetness due to their limited number of taste receptors.\n",
      "12. Many pets, such as cats and dogs, are able to recognize and respond to their owner's voice within the first few weeks of being adopted.\n",
      "\n",
      "**Pet-Related Statistics**\n",
      "\n",
      "13. The global pet food market is projected to reach $130 billion by 2025.\n",
      "14. In the United States alone, there are over 1 million veterinarians.\n",
      "15. According to a survey, Americans spend an estimated $75 billion on pets each year.\n"
     ]
    }
   ],
   "source": [
    "# Original query\n",
    "original_query = \"Tell me about pets.\"\n",
    "\n",
    "# Step 1: Generate additional information about the query\n",
    "generated_information = generate_text(\n",
    "    \"Generate some facts about the following query: \"\n",
    "    + original_query\n",
    "    + \"--- Only return the facts\"\n",
    ")\n",
    "\n",
    "print(generated_information)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
